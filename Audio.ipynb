{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyaudio\n",
    "# !pip install wave\n",
    "# !pip install transformers torchaudio soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jellyboi/anaconda3/envs/textS/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer, T5ForConditionalGeneration, T5Tokenizer\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained speech-to-text model and tokenizer\n",
    "local_model_path = \"./wav2vec2-large-960h\"\n",
    "local_tokenizer_path = \"./wav2vec2-large-960h\"\n",
    "model_name = \"facebook/wav2vec2-large-960h\"\n",
    "\n",
    "if not os.path.exists(local_model_path):\n",
    "    os.makedirs(local_model_path)\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
    "    model.save_pretrained(local_model_path)\n",
    "    tokenizer = Wav2Vec2Tokenizer.from_pretrained(model_name)\n",
    "    tokenizer.save_pretrained(local_tokenizer_path)\n",
    "else:\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(local_model_path)\n",
    "    tokenizer = Wav2Vec2Tokenizer.from_pretrained(local_tokenizer_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transcribe_audio(file_path):\n",
    "    try:\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "        if sample_rate != 16000:\n",
    "            transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "            waveform = transform(waveform)\n",
    "        input_values = tokenizer(waveform.squeeze().numpy(), return_tensors=\"pt\").input_values\n",
    "        logits = model(input_values).logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = tokenizer.batch_decode(predicted_ids)[0]\n",
    "        return transcription\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "def summarize_text(text):\n",
    "    tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "    model = T5ForConditionalGeneration.from_pretrained('./t5_base_trained')\n",
    "    # Tokenize the input dialogue\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs, max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
    "    generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return generated_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_and_summarize(file_path):\n",
    "    transcription = transcribe_audio(file_path)\n",
    "    if transcription:\n",
    "        summary = summarize_text(transcription)\n",
    "        return transcription, summary\n",
    "    return None, None\n",
    "\n",
    "# Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: ALEX HAY BOB ARE YOU HEADING TO THE GIM TO DAY BOB I WAS PLANNING TO BUT THE WEATHER IS SO HUMAN AND WET IT'S ALMOST UNBEARABLE ALEX TELL ME ABOUT IT I TEPED OUTSIDE FOR A MINUTE AND FELT LIKE I WAS IN ASANA BOB EXACTLY I DON'T THINK I CAN HANDLE A WORK OUT IN THIS KIND OF WEATHER IT'S JUST TOO UNCOMFORTABLE ALEX SAME HERE MAYBE WE SHOULD JUST SKIP THE JIM TO DAY AND DO SOME LIGHT EXERCISES AT HOME INSTEAD BOB THAT SOUNDS LIKE A GOOD IDEA WE CAN STILL STAY ACTIVE WITHOUT SUFFERING IN THIS HUMIITY ALEX AGREED I'LL DO SOME YOGA AND BODYWEIGHT EXERCISES WHAT ABOUT YOU BOB I MIGHT DO THE SAME PLUS IT GIVES US AN EXCUSE TO AVOID THE WEATHER ALEX TRUE LET'S STAY COOL AND AVOID THE HUMIDITY BOB DEFINITELY SEE YOU TOMORROW HOPEFULLY WITH BETTER WEATHER ALEX FEGER'S CROSSED TAKE CARE BOB BOB YOU TOO ALEX\n",
      "Summary: ALEX HAY IS HEADING TO THE GIM TO DAY. He TEPED OUTSIDE for a minute and felt like he was in ASANA.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"Recording3.mp3\"\n",
    "transcription, summary = transcribe_and_summarize(file_path)\n",
    "print(\"Transcription:\", transcription)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
